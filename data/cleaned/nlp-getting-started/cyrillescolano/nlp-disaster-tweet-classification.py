import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
import missingno as msno
import warnings
warnings.filterwarnings('ignore')
import re
import re
import string
import nltk
from nltk.corpus import stopwords
from sklearn import model_selection
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import f1_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.multioutput import MultiOutputClassifier
from sklearn.model_selection import RepeatedStratifiedKFold
import nltk
from nltk.tokenize import word_tokenize, RegexpTokenizer
from nltk.stem import WordNetLemmatizer
from platform import python_version
print(python_version())
train = pd.read_csv('data/input/nlp-getting-started/train.csv')
test = pd.read_csv('data/input/nlp-getting-started/test.csv')
sub_sample = pd.read_csv('data/input/nlp-getting-started/sample_submission.csv')
print(train.shape, test.shape, sub_sample.shape)
train.info()
train.head()
print(train.duplicated().sum())
print(test.duplicated().sum())

def missing_values(df):
    """Input- df=pandas dataframe
       Output- print missing records count and % of the input dataframe and visualize using MSNO
    """
    print('Number of records with missing location:', df.location.isnull().sum())
    print('Number of records with missing keywords:', df.keyword.isnull().sum())
    print('{}% of location values are missing from Total Number of Records.'.format(round(df.location.isnull().sum() / df.shape[0] * 100), 2))
    print('{}% of keywords values are missing from Total Number of Records.'.format(round(df.keyword.isnull().sum() / df.shape[0] * 100), 2))
    ''
missing_values(train)
missing_values(test)
missing_cols = ['keyword', 'location']
(fig, axes) = plt.subplots(ncols=2, figsize=(17, 4), dpi=100)
sns.barplot(x=train[missing_cols].isnull().sum().index, y=train[missing_cols].isnull().sum().values, ax=axes[0])
sns.barplot(x=test[missing_cols].isnull().sum().index, y=test[missing_cols].isnull().sum().values, ax=axes[1])
axes[0].set_ylabel('Missing Value Count', size=15, labelpad=20)
axes[0].tick_params(axis='x', labelsize=15)
axes[0].tick_params(axis='y', labelsize=15)
axes[1].tick_params(axis='x', labelsize=15)
axes[1].tick_params(axis='y', labelsize=15)
axes[0].set_title('Training Set', fontsize=13)
axes[1].set_title('Test Set', fontsize=13)

for df in [train, test]:
    for col in ['keyword', 'location']:
        df[col] = df[col].fillna(f'no_{col}')
sns.countplot(x='target', data=train)
print('Target of 0 is {} % of total'.format(round(train['target'].value_counts()[0] / len(train['target']) * 100)))
print('Target of 1 is {} % of total'.format(round(train['target'].value_counts()[1] / len(train['target']) * 100)))
feat = train['keyword'].value_counts()
print(feat.head())
fig = px.scatter(feat, x=feat.values, y=feat.index, size=feat.values)
fig.show()
feat = train['location'].value_counts()
print(feat.head())
fig = px.scatter(feat, x=feat.values, y=feat.index, size=feat.values)
fig.show()
loc_dict = {'United States': 'USA', 'New York': 'USA', 'London': 'UK', 'Los Angeles, CA': 'USA', 'Washington, D.C.': 'USA', 'California': 'USA', 'Chicago, IL': 'USA', 'Chicago': 'USA', 'New York, NY': 'USA', 'California, USA': 'USA', 'FLorida': 'USA', 'Nigeria': 'Africa', 'Kenya': 'Africa', 'Everywhere': 'Worldwide', 'San Francisco': 'USA', 'Florida': 'USA', 'United Kingdom': 'UK', 'Los Angeles': 'USA', 'Toronto': 'Canada', 'San Francisco, CA': 'USA', 'NYC': 'USA', 'Seattle': 'USA', 'Earth': 'Worldwide', 'Ireland': 'UK', 'London, England': 'UK', 'New York City': 'USA', 'Texas': 'USA', 'London, UK': 'UK', 'Atlanta, GA': 'USA', 'Mumbai': 'India'}
train['location'].replace(loc_dict, inplace=True)
sns.barplot(y=train['location'].value_counts()[:10].index, x=train['location'].value_counts()[:10], orient='h')
train = train.drop(['location'], axis=1)
train.head()
train['tweet_len'] = train['text'].apply(lambda x: len(x))
train.head(4)
train.tweet_len.describe()
ax = sns.distplot(train['tweet_len']).set_title('Distribution of the tweet lengths')
plt.grid(True)
(f, (ax1, ax2)) = plt.subplots(1, 2, sharex=True, figsize=(10, 6))
sns.distplot(train[train['target'] == 1]['tweet_len'], ax=ax1, kde=False, color='green', label='Disater texts')
sns.distplot(train[train['target'] == 0]['tweet_len'], ax=ax2, kde=False, color='red', label='Non-Disater texts')
f.suptitle('tweet length distribution')
f.legend(loc='upper right')
ax1.grid()
ax2.grid()

(fig, (ax1, ax2)) = plt.subplots(1, 2, figsize=(10, 5))
dis_text = train[train['target'] == 1]['text'].str.split().map(lambda x: len(x))
ax1.hist(dis_text, color='blue')
ax1.set_title('Disaster tweets')
ax1.grid()
nondis_text = train[train['target'] == 0]['text'].str.split().map(lambda x: len(x))
ax2.hist(nondis_text, color='red')
ax2.set_title('Non-disaster tweets')
ax2.grid()
fig.suptitle('Words in a text')

train[train['target'] == 1]['text'][10:20]
train[train['target'] == 0]['text'][10:20]
train['text'][:10]

def clean_text(text):
    """
    Input- 'text' to be cleaned
       
       Output- Convert input 'text' to lowercase,remove square brackets,links,punctuation
       and words containing numbers. Return clean text.
    
    """
    text = text.lower()
    text = re.sub('\\[.*?\\]', '', text)
    text = re.sub('https?://\\S+|www\\.\\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\\w*\\d\\w*', '', text)
    text = re.sub('\\x89Û_', '', text)
    text = re.sub('\\x89ÛÒ', '', text)
    text = re.sub('\\x89ÛÓ', '', text)
    text = re.sub('\\x89ÛÏWhen', 'When', text)
    text = re.sub('\\x89ÛÏ', '', text)
    text = re.sub('China\\x89Ûªs', "China's", text)
    text = re.sub('let\\x89Ûªs', "let's", text)
    text = re.sub('\\x89Û÷', '', text)
    text = re.sub('\\x89Ûª', '', text)
    text = re.sub('\\x89Û\\x9d', '', text)
    text = re.sub('å_', '', text)
    text = re.sub('\\x89Û¢', '', text)
    text = re.sub('\\x89Û¢åÊ', '', text)
    text = re.sub('fromåÊwounds', 'from wounds', text)
    text = re.sub('åÊ', '', text)
    text = re.sub('åÈ', '', text)
    text = re.sub('JapÌ_n', 'Japan', text)
    text = re.sub('Ì©', 'e', text)
    text = re.sub('å¨', '', text)
    text = re.sub('SuruÌ¤', 'Suruc', text)
    text = re.sub('åÇ', '', text)
    text = re.sub('å£3million', '3 million', text)
    text = re.sub('åÀ', '', text)
    text = re.sub("he's", 'he is', text)
    text = re.sub("there's", 'there is', text)
    text = re.sub("We're", 'We are', text)
    text = re.sub("That's", 'That is', text)
    text = re.sub("won't", 'will not', text)
    text = re.sub("they're", 'they are', text)
    text = re.sub("Can't", 'Cannot', text)
    text = re.sub("wasn't", 'was not', text)
    text = re.sub('don\\x89Ûªt', 'do not', text)
    text = re.sub("aren't", 'are not', text)
    text = re.sub("isn't", 'is not', text)
    text = re.sub("What's", 'What is', text)
    text = re.sub("haven't", 'have not', text)
    text = re.sub("hasn't", 'has not', text)
    text = re.sub("There's", 'There is', text)
    text = re.sub("He's", 'He is', text)
    text = re.sub("It's", 'It is', text)
    text = re.sub("You're", 'You are', text)
    text = re.sub("I'M", 'I am', text)
    text = re.sub("shouldn't", 'should not', text)
    text = re.sub("wouldn't", 'would not', text)
    text = re.sub("i'm", 'I am', text)
    text = re.sub('I\\x89Ûªm', 'I am', text)
    text = re.sub("I'm", 'I am', text)
    text = re.sub("Isn't", 'is not', text)
    text = re.sub("Here's", 'Here is', text)
    text = re.sub("you've", 'you have', text)
    text = re.sub('you\\x89Ûªve', 'you have', text)
    text = re.sub("we're", 'we are', text)
    text = re.sub("what's", 'what is', text)
    text = re.sub("couldn't", 'could not', text)
    text = re.sub("we've", 'we have', text)
    text = re.sub('it\\x89Ûªs', 'it is', text)
    text = re.sub('doesn\\x89Ûªt', 'does not', text)
    text = re.sub('It\\x89Ûªs', 'It is', text)
    text = re.sub('Here\\x89Ûªs', 'Here is', text)
    text = re.sub("who's", 'who is', text)
    text = re.sub('I\\x89Ûªve', 'I have', text)
    text = re.sub("y'all", 'you all', text)
    text = re.sub('can\\x89Ûªt', 'cannot', text)
    text = re.sub("would've", 'would have', text)
    text = re.sub("it'll", 'it will', text)
    text = re.sub("we'll", 'we will', text)
    text = re.sub('wouldn\\x89Ûªt', 'would not', text)
    text = re.sub("We've", 'We have', text)
    text = re.sub("he'll", 'he will', text)
    text = re.sub("Y'all", 'You all', text)
    text = re.sub("Weren't", 'Were not', text)
    text = re.sub("Didn't", 'Did not', text)
    text = re.sub("they'll", 'they will', text)
    text = re.sub("they'd", 'they would', text)
    text = re.sub("DON'T", 'DO NOT', text)
    text = re.sub('That\\x89Ûªs', 'That is', text)
    text = re.sub("they've", 'they have', text)
    text = re.sub("i'd", 'I would', text)
    text = re.sub("should've", 'should have', text)
    text = re.sub('You\\x89Ûªre', 'You are', text)
    text = re.sub("where's", 'where is', text)
    text = re.sub('Don\\x89Ûªt', 'Do not', text)
    text = re.sub("we'd", 'we would', text)
    text = re.sub("i'll", 'I will', text)
    text = re.sub("weren't", 'were not', text)
    text = re.sub("They're", 'They are', text)
    text = re.sub('Can\\x89Ûªt', 'Cannot', text)
    text = re.sub('you\\x89Ûªll', 'you will', text)
    text = re.sub('I\\x89Ûªd', 'I would', text)
    text = re.sub("let's", 'let us', text)
    text = re.sub("it's", 'it is', text)
    text = re.sub("can't", 'cannot', text)
    text = re.sub("don't", 'do not', text)
    text = re.sub("you're", 'you are', text)
    text = re.sub("i've", 'I have', text)
    text = re.sub("that's", 'that is', text)
    text = re.sub("i'll", 'I will', text)
    text = re.sub("doesn't", 'does not', text)
    text = re.sub("i'd", 'I would', text)
    text = re.sub("didn't", 'did not', text)
    text = re.sub("ain't", 'am not', text)
    text = re.sub("you'll", 'you will', text)
    text = re.sub("I've", 'I have', text)
    text = re.sub("Don't", 'do not', text)
    text = re.sub("I'll", 'I will', text)
    text = re.sub("I'd", 'I would', text)
    text = re.sub("Let's", 'Let us', text)
    text = re.sub("you'd", 'You would', text)
    text = re.sub("It's", 'It is', text)
    text = re.sub("Ain't", 'am not', text)
    text = re.sub("Haven't", 'Have not', text)
    text = re.sub("Could've", 'Could have', text)
    text = re.sub('youve', 'you have', text)
    text = re.sub('donå«t', 'do not', text)
    text = re.sub('&gt;', '>', text)
    text = re.sub('&lt;', '<', text)
    text = re.sub('&amp;', '&', text)
    text = re.sub('w/e', 'whatever', text)
    text = re.sub('w/', 'with', text)
    text = re.sub('USAgov', 'USA government', text)
    text = re.sub('recentlu', 'recently', text)
    text = re.sub('Ph0tos', 'Photos', text)
    text = re.sub('amirite', 'am I right', text)
    text = re.sub('exp0sed', 'exposed', text)
    text = re.sub('<3', 'love', text)
    text = re.sub('amageddon', 'armageddon', text)
    text = re.sub('Trfc', 'Traffic', text)
    text = re.sub('8/5/2015', '2015-08-05', text)
    text = re.sub('WindStorm', 'Wind Storm', text)
    text = re.sub('8/6/2015', '2015-08-06', text)
    text = re.sub('10:38PM', '10:38 PM', text)
    text = re.sub('10:30pm', '10:30 PM', text)
    text = re.sub('16yr', '16 year', text)
    text = re.sub('lmao', 'laughing my ass off', text)
    text = re.sub('TRAUMATISED', 'traumatized', text)
    text = re.sub('IranDeal', 'Iran Deal', text)
    text = re.sub('ArianaGrande', 'Ariana Grande', text)
    text = re.sub('camilacabello97', 'camila cabello', text)
    text = re.sub('RondaRousey', 'Ronda Rousey', text)
    text = re.sub('MTVHottest', 'MTV Hottest', text)
    text = re.sub('TrapMusic', 'Trap Music', text)
    text = re.sub('ProphetMuhammad', 'Prophet Muhammad', text)
    text = re.sub('PantherAttack', 'Panther Attack', text)
    text = re.sub('StrategicPatience', 'Strategic Patience', text)
    text = re.sub('socialnews', 'social news', text)
    text = re.sub('NASAHurricane', 'NASA Hurricane', text)
    text = re.sub('onlinecommunities', 'online communities', text)
    text = re.sub('humanconsumption', 'human consumption', text)
    text = re.sub('Typhoon-Devastated', 'Typhoon Devastated', text)
    text = re.sub('Meat-Loving', 'Meat Loving', text)
    text = re.sub('facialabuse', 'facial abuse', text)
    text = re.sub('LakeCounty', 'Lake County', text)
    text = re.sub('BeingAuthor', 'Being Author', text)
    text = re.sub('withheavenly', 'with heavenly', text)
    text = re.sub('thankU', 'thank you', text)
    text = re.sub('iTunesMusic', 'iTunes Music', text)
    text = re.sub('OffensiveContent', 'Offensive Content', text)
    text = re.sub('WorstSummerJob', 'Worst Summer Job', text)
    text = re.sub('HarryBeCareful', 'Harry Be Careful', text)
    text = re.sub('NASASolarSystem', 'NASA Solar System', text)
    text = re.sub('animalrescue', 'animal rescue', text)
    text = re.sub('KurtSchlichter', 'Kurt Schlichter', text)
    text = re.sub('aRmageddon', 'armageddon', text)
    text = re.sub('Throwingknifes', 'Throwing knives', text)
    text = re.sub('GodsLove', "God's Love", text)
    text = re.sub('bookboost', 'book boost', text)
    text = re.sub('ibooklove', 'I book love', text)
    text = re.sub('NestleIndia', 'Nestle India', text)
    text = re.sub('realDonaldTrump', 'Donald Trump', text)
    text = re.sub('DavidVonderhaar', 'David Vonderhaar', text)
    text = re.sub('CecilTheLion', 'Cecil The Lion', text)
    text = re.sub('weathernetwork', 'weather network', text)
    text = re.sub('withBioterrorism&use', 'with Bioterrorism & use', text)
    text = re.sub('Hostage&2', 'Hostage & 2', text)
    text = re.sub('GOPDebate', 'GOP Debate', text)
    text = re.sub('RickPerry', 'Rick Perry', text)
    text = re.sub('frontpage', 'front page', text)
    text = re.sub('NewsIntexts', 'News In texts', text)
    text = re.sub('ViralSpell', 'Viral Spell', text)
    text = re.sub('til_now', 'until now', text)
    text = re.sub('volcanoinRussia', 'volcano in Russia', text)
    text = re.sub('ZippedNews', 'Zipped News', text)
    text = re.sub('MicheleBachman', 'Michele Bachman', text)
    text = re.sub('53inch', '53 inch', text)
    text = re.sub('KerrickTrial', 'Kerrick Trial', text)
    text = re.sub('abstorm', 'Alberta Storm', text)
    text = re.sub('Beyhive', 'Beyonce hive', text)
    text = re.sub('IDFire', 'Idaho Fire', text)
    text = re.sub('DETECTADO', 'Detected', text)
    text = re.sub('RockyFire', 'Rocky Fire', text)
    text = re.sub('Listen/Buy', 'Listen / Buy', text)
    text = re.sub('NickCannon', 'Nick Cannon', text)
    text = re.sub('FaroeIslands', 'Faroe Islands', text)
    text = re.sub('yycstorm', 'Calgary Storm', text)
    text = re.sub('IDPs:', 'Internally Displaced People :', text)
    text = re.sub('ArtistsUnited', 'Artists United', text)
    text = re.sub('ClaytonBryant', 'Clayton Bryant', text)
    text = re.sub('jimmyfallon', 'jimmy fallon', text)
    text = re.sub('justinbieber', 'justin bieber', text)
    text = re.sub('UTC2015', 'UTC 2015', text)
    text = re.sub('Time2015', 'Time 2015', text)
    text = re.sub('djicemoon', 'dj icemoon', text)
    text = re.sub('LivingSafely', 'Living Safely', text)
    text = re.sub('FIFA16', 'Fifa 2016', text)
    text = re.sub('thisiswhywecanthavenicethings', 'this is why we cannot have nice things', text)
    text = re.sub('bbcnews', 'bbc news', text)
    text = re.sub('UndergroundRailraod', 'Underground Railraod', text)
    text = re.sub('c4news', 'c4 news', text)
    text = re.sub('OBLITERATION', 'obliteration', text)
    text = re.sub('MUDSLIDE', 'mudslide', text)
    text = re.sub('NoSurrender', 'No Surrender', text)
    text = re.sub('NotExplained', 'Not Explained', text)
    text = re.sub('greatbritishbakeoff', 'great british bake off', text)
    text = re.sub('LondonFire', 'London Fire', text)
    text = re.sub('KOTAWeather', 'KOTA Weather', text)
    text = re.sub('LuchaUnderground', 'Lucha Underground', text)
    text = re.sub('KOIN6News', 'KOIN 6 News', text)
    text = re.sub('LiveOnK2', 'Live On K2', text)
    text = re.sub('9NewsGoldCoast', '9 News Gold Coast', text)
    text = re.sub('nikeplus', 'nike plus', text)
    text = re.sub('david_cameron', 'David Cameron', text)
    text = re.sub('peterjukes', 'Peter Jukes', text)
    text = re.sub('JamesMelville', 'James Melville', text)
    text = re.sub('megynkelly', 'Megyn Kelly', text)
    text = re.sub('cnewslive', 'C News Live', text)
    text = re.sub('JamaicaObserver', 'Jamaica Observer', text)
    text = re.sub('textLikeItsSeptember11th2001', 'text like it is september 11th 2001', text)
    text = re.sub('cbplawyers', 'cbp lawyers', text)
    text = re.sub('fewmoretexts', 'few more texts', text)
    text = re.sub('BlackLivesMatter', 'Black Lives Matter', text)
    text = re.sub('cjoyner', 'Chris Joyner', text)
    text = re.sub('ENGvAUS', 'England vs Australia', text)
    text = re.sub('ScottWalker', 'Scott Walker', text)
    text = re.sub('MikeParrActor', 'Michael Parr', text)
    text = re.sub('4PlayThursdays', 'Foreplay Thursdays', text)
    text = re.sub('TGF2015', 'Tontitown Grape Festival', text)
    text = re.sub('realmandyrain', 'Mandy Rain', text)
    text = re.sub('GraysonDolan', 'Grayson Dolan', text)
    text = re.sub('ApolloBrown', 'Apollo Brown', text)
    text = re.sub('saddlebrooke', 'Saddlebrooke', text)
    text = re.sub('TontitownGrape', 'Tontitown Grape', text)
    text = re.sub('AbbsWinston', 'Abbs Winston', text)
    text = re.sub('ShaunKing', 'Shaun King', text)
    text = re.sub('MeekMill', 'Meek Mill', text)
    text = re.sub('TornadoGiveaway', 'Tornado Giveaway', text)
    text = re.sub('GRupdates', 'GR updates', text)
    text = re.sub('SouthDowns', 'South Downs', text)
    text = re.sub('braininjury', 'brain injury', text)
    text = re.sub('auspol', 'Australian politics', text)
    text = re.sub('PlannedParenthood', 'Planned Parenthood', text)
    text = re.sub('calgaryweather', 'Calgary Weather', text)
    text = re.sub('weallheartonedirection', 'we all heart one direction', text)
    text = re.sub('edsheeran', 'Ed Sheeran', text)
    text = re.sub('TrueHeroes', 'True Heroes', text)
    text = re.sub('S3XLEAK', 'sex leak', text)
    text = re.sub('ComplexMag', 'Complex Magazine', text)
    text = re.sub('TheAdvocateMag', 'The Advocate Magazine', text)
    text = re.sub('CityofCalgary', 'City of Calgary', text)
    text = re.sub('EbolaOutbreak', 'Ebola Outbreak', text)
    text = re.sub('SummerFate', 'Summer Fate', text)
    text = re.sub('RAmag', 'Royal Academy Magazine', text)
    text = re.sub('offers2go', 'offers to go', text)
    text = re.sub('foodscare', 'food scare', text)
    text = re.sub('MNPDNashville', 'Metropolitan Nashville Police Department', text)
    text = re.sub('TfLBusAlerts', 'TfL Bus Alerts', text)
    text = re.sub('GamerGate', 'Gamer Gate', text)
    text = re.sub('IHHen', 'Humanitarian Relief', text)
    text = re.sub('spinningbot', 'spinning bot', text)
    text = re.sub('ModiMinistry', 'Modi Ministry', text)
    text = re.sub('TAXIWAYS', 'taxi ways', text)
    text = re.sub('Calum5SOS', 'Calum Hood', text)
    text = re.sub('po_st', 'po.st', text)
    text = re.sub('scoopit', 'scoop.it', text)
    text = re.sub('UltimaLucha', 'Ultima Lucha', text)
    text = re.sub('JonathanFerrell', 'Jonathan Ferrell', text)
    text = re.sub('aria_ahrary', 'Aria Ahrary', text)
    text = re.sub('rapidcity', 'Rapid City', text)
    text = re.sub('OutBid', 'outbid', text)
    text = re.sub('lavenderpoetrycafe', 'lavender poetry cafe', text)
    text = re.sub('EudryLantiqua', 'Eudry Lantiqua', text)
    text = re.sub('15PM', '15 PM', text)
    text = re.sub('OriginalFunko', 'Funko', text)
    text = re.sub('rightwaystan', 'Richard Tan', text)
    text = re.sub('CindyNoonan', 'Cindy Noonan', text)
    text = re.sub('RT_America', 'RT America', text)
    text = re.sub('narendramodi', 'Narendra Modi', text)
    text = re.sub('BakeOffFriends', 'Bake Off Friends', text)
    text = re.sub('TeamHendrick', 'Hendrick Motorsports', text)
    text = re.sub('alexbelloli', 'Alex Belloli', text)
    text = re.sub('itsjustinstuart', 'Justin Stuart', text)
    text = re.sub('gunsense', 'gun sense', text)
    text = re.sub('DebateQuestionsWeWantToHear', 'debate questions we want to hear', text)
    text = re.sub('RoyalCarribean', 'Royal Carribean', text)
    text = re.sub('samanthaturne19', 'Samantha Turner', text)
    text = re.sub('JonVoyage', 'Jon Stewart', text)
    text = re.sub('renew911health', 'renew 911 health', text)
    text = re.sub('SuryaRay', 'Surya Ray', text)
    text = re.sub('pattonoswalt', 'Patton Oswalt', text)
    text = re.sub('minhazmerchant', 'Minhaz Merchant', text)
    text = re.sub('TLVFaces', 'Israel Diaspora Coalition', text)
    text = re.sub('pmarca', 'Marc Andreessen', text)
    text = re.sub('pdx911', 'Portland Police', text)
    text = re.sub('jamaicaplain', 'Jamaica Plain', text)
    text = re.sub('Japton', 'Arkansas', text)
    text = re.sub('RouteComplex', 'Route Complex', text)
    text = re.sub('INSubcontinent', 'Indian Subcontinent', text)
    text = re.sub('NJTurnpike', 'New Jersey Turnpike', text)
    text = re.sub('Politifiact', 'PolitiFact', text)
    text = re.sub('Hiroshima70', 'Hiroshima', text)
    text = re.sub('GMMBC', 'Greater Mt Moriah Baptist Church', text)
    text = re.sub('versethe', 'verse the', text)
    text = re.sub('TubeStrike', 'Tube Strike', text)
    text = re.sub('MissionHills', 'Mission Hills', text)
    text = re.sub('ProtectDenaliWolves', 'Protect Denali Wolves', text)
    text = re.sub('NANKANA', 'Nankana', text)
    text = re.sub('SAHIB', 'Sahib', text)
    text = re.sub('PAKPATTAN', 'Pakpattan', text)
    text = re.sub('Newz_Sacramento', 'News Sacramento', text)
    text = re.sub('gofundme', 'go fund me', text)
    text = re.sub('pmharper', 'Stephen Harper', text)
    text = re.sub('IvanBerroa', 'Ivan Berroa', text)
    text = re.sub('LosDelSonido', 'Los Del Sonido', text)
    text = re.sub('bancodeseries', 'banco de series', text)
    text = re.sub('timkaine', 'Tim Kaine', text)
    text = re.sub('IdentityTheft', 'Identity Theft', text)
    text = re.sub('AllLivesMatter', 'All Lives Matter', text)
    text = re.sub('mishacollins', 'Misha Collins', text)
    text = re.sub('BillNeelyNBC', 'Bill Neely', text)
    text = re.sub('BeClearOnCancer', 'be clear on cancer', text)
    text = re.sub('Kowing', 'Knowing', text)
    text = re.sub('ScreamQueens', 'Scream Queens', text)
    text = re.sub('AskCharley', 'Ask Charley', text)
    text = re.sub('BlizzHeroes', 'Heroes of the Storm', text)
    text = re.sub('BradleyBrad47', 'Bradley Brad', text)
    text = re.sub('HannaPH', 'Typhoon Hanna', text)
    text = re.sub('meinlcymbals', 'MEINL Cymbals', text)
    text = re.sub('Ptbo', 'Peterborough', text)
    text = re.sub('cnnbrk', 'CNN Breaking News', text)
    text = re.sub('IndianNews', 'Indian News', text)
    text = re.sub('savebees', 'save bees', text)
    text = re.sub('GreenHarvard', 'Green Harvard', text)
    text = re.sub('StandwithPP', 'Stand with planned parenthood', text)
    text = re.sub('hermancranston', 'Herman Cranston', text)
    text = re.sub('WMUR9', 'WMUR-TV', text)
    text = re.sub('RockBottomRadFM', 'Rock Bottom Radio', text)
    text = re.sub('ameenshaikh3', 'Ameen Shaikh', text)
    text = re.sub('ProSyn', 'Project Syndicate', text)
    text = re.sub('Daesh', 'ISIS', text)
    text = re.sub('s2g', 'swear to god', text)
    text = re.sub('listenlive', 'listen live', text)
    text = re.sub('CDCgov', 'Centers for Disease Control and Prevention', text)
    text = re.sub('FoxNew', 'Fox News', text)
    text = re.sub('CBSBigBrother', 'Big Brother', text)
    text = re.sub('JulieDiCaro', 'Julie DiCaro', text)
    text = re.sub('theadvocatemag', 'The Advocate Magazine', text)
    text = re.sub('RohnertParkDPS', 'Rohnert Park Police Department', text)
    text = re.sub('THISIZBWRIGHT', 'Bonnie Wright', text)
    text = re.sub('Popularmmos', 'Popular MMOs', text)
    text = re.sub('WildHorses', 'Wild Horses', text)
    text = re.sub('FantasticFour', 'Fantastic Four', text)
    text = re.sub('HORNDALE', 'Horndale', text)
    text = re.sub('PINER', 'Piner', text)
    text = re.sub('BathAndNorthEastSomerset', 'Bath and North East Somerset', text)
    text = re.sub('thatswhatfriendsarefor', 'that is what friends are for', text)
    text = re.sub('residualincome', 'residual income', text)
    text = re.sub('YahooNewsDigest', 'Yahoo News Digest', text)
    text = re.sub('MalaysiaAirlines', 'Malaysia Airlines', text)
    text = re.sub('AmazonDeals', 'Amazon Deals', text)
    text = re.sub('MissCharleyWebb', 'Charley Webb', text)
    text = re.sub('shoalstraffic', 'shoals traffic', text)
    text = re.sub('GeorgeFoster72', 'George Foster', text)
    text = re.sub('pop2015', 'pop 2015', text)
    text = re.sub('_PokemonCards_', 'Pokemon Cards', text)
    text = re.sub('DianneG', 'Dianne Gallagher', text)
    text = re.sub('KashmirConflict', 'Kashmir Conflict', text)
    text = re.sub('BritishBakeOff', 'British Bake Off', text)
    text = re.sub('FreeKashmir', 'Free Kashmir', text)
    text = re.sub('mattmosley', 'Matt Mosley', text)
    text = re.sub('BishopFred', 'Bishop Fred', text)
    text = re.sub('EndConflict', 'End Conflict', text)
    text = re.sub('EndOccupation', 'End Occupation', text)
    text = re.sub('UNHEALED', 'unhealed', text)
    text = re.sub('CharlesDagnall', 'Charles Dagnall', text)
    text = re.sub('Latestnews', 'Latest news', text)
    text = re.sub('KindleCountdown', 'Kindle Countdown', text)
    text = re.sub('NoMoreHandouts', 'No More Handouts', text)
    text = re.sub('datingtips', 'dating tips', text)
    text = re.sub('charlesadler', 'Charles Adler', text)
    text = re.sub('twia', 'Texas Windstorm Insurance Association', text)
    text = re.sub('txlege', 'Texas Legislature', text)
    text = re.sub('WindstormInsurer', 'Windstorm Insurer', text)
    text = re.sub('Newss', 'News', text)
    text = re.sub('hempoil', 'hemp oil', text)
    text = re.sub('CommoditiesAre', 'Commodities are', text)
    text = re.sub('tubestrike', 'tube strike', text)
    text = re.sub('JoeNBC', 'Joe Scarborough', text)
    text = re.sub('LiteraryCakes', 'Literary Cakes', text)
    text = re.sub('TI5', 'The International 5', text)
    text = re.sub('thehill', 'the hill', text)
    text = re.sub('3others', '3 others', text)
    text = re.sub('stighefootball', 'Sam Tighe', text)
    text = re.sub('whatstheimportantvideo', 'what is the important video', text)
    text = re.sub('ClaudioMeloni', 'Claudio Meloni', text)
    text = re.sub('DukeSkywalker', 'Duke Skywalker', text)
    text = re.sub('carsonmwr', 'Fort Carson', text)
    text = re.sub('offdishduty', 'off dish duty', text)
    text = re.sub('andword', 'and word', text)
    text = re.sub('rhodeisland', 'Rhode Island', text)
    text = re.sub('easternoregon', 'Eastern Oregon', text)
    text = re.sub('WAwildfire', 'Washington Wildfire', text)
    text = re.sub('fingerrockfire', 'Finger Rock Fire', text)
    text = re.sub('57am', '57 am', text)
    text = re.sub('fingerrockfire', 'Finger Rock Fire', text)
    text = re.sub('JacobHoggard', 'Jacob Hoggard', text)
    text = re.sub('newnewnew', 'new new new', text)
    text = re.sub('under50', 'under 50', text)
    text = re.sub('getitbeforeitsgone', 'get it before it is gone', text)
    text = re.sub('freshoutofthebox', 'fresh out of the box', text)
    text = re.sub('amwriting', 'am writing', text)
    text = re.sub('Bokoharm', 'Boko Haram', text)
    text = re.sub('Nowlike', 'Now like', text)
    text = re.sub('seasonfrom', 'season from', text)
    text = re.sub('epicente', 'epicenter', text)
    text = re.sub('epicenterr', 'epicenter', text)
    text = re.sub('sicklife', 'sick life', text)
    text = re.sub('yycweather', 'Calgary Weather', text)
    text = re.sub('calgarysun', 'Calgary Sun', text)
    text = re.sub('approachng', 'approaching', text)
    text = re.sub('evng', 'evening', text)
    text = re.sub('Sumthng', 'something', text)
    text = re.sub('EllenPompeo', 'Ellen Pompeo', text)
    text = re.sub('shondarhimes', 'Shonda Rhimes', text)
    text = re.sub('ABCNetwork', 'ABC Network', text)
    text = re.sub('SushmaSwaraj', 'Sushma Swaraj', text)
    text = re.sub('pray4japan', 'Pray for Japan', text)
    text = re.sub('hope4japan', 'Hope for Japan', text)
    text = re.sub('Illusionimagess', 'Illusion images', text)
    text = re.sub('SummerUnderTheStars', 'Summer Under The Stars', text)
    text = re.sub('ShallWeDance', 'Shall We Dance', text)
    text = re.sub('TCMParty', 'TCM Party', text)
    text = re.sub('marijuananews', 'marijuana news', text)
    text = re.sub('onbeingwithKristaTippett', 'on being with Krista Tippett', text)
    text = re.sub('Beingtexts', 'Being texts', text)
    text = re.sub('newauthors', 'new authors', text)
    text = re.sub('remedyyyy', 'remedy', text)
    text = re.sub('44PM', '44 PM', text)
    text = re.sub('HeadlinesApp', 'Headlines App', text)
    text = re.sub('40PM', '40 PM', text)
    text = re.sub('myswc', 'Severe Weather Center', text)
    text = re.sub('ithats', 'that is', text)
    text = re.sub('icouldsitinthismomentforever', 'I could sit in this moment forever', text)
    text = re.sub('FatLoss', 'Fat Loss', text)
    text = re.sub('02PM', '02 PM', text)
    text = re.sub('MetroFmTalk', 'Metro Fm Talk', text)
    text = re.sub('Bstrd', 'bastard', text)
    text = re.sub('bldy', 'bloody', text)
    text = re.sub('MetrofmTalk', 'Metro Fm Talk', text)
    text = re.sub('terrorismturn', 'terrorism turn', text)
    text = re.sub('BBCNewsAsia', 'BBC News Asia', text)
    text = re.sub('BehindTheScenes', 'Behind The Scenes', text)
    text = re.sub('GeorgeTakei', 'George Takei', text)
    text = re.sub('WomensWeeklyMag', 'Womens Weekly Magazine', text)
    text = re.sub('SurvivorsGuidetoEarth', 'Survivors Guide to Earth', text)
    text = re.sub('incubusband', 'incubus band', text)
    text = re.sub('Babypicturethis', 'Baby picture this', text)
    text = re.sub('BombEffects', 'Bomb Effects', text)
    text = re.sub('win10', 'Windows 10', text)
    text = re.sub('idkidk', 'I do not know I do not know', text)
    text = re.sub('TheWalkingDead', 'The Walking Dead', text)
    text = re.sub('amyschumer', 'Amy Schumer', text)
    text = re.sub('crewlist', 'crew list', text)
    text = re.sub('Erdogans', 'Erdogan', text)
    text = re.sub('BBCLive', 'BBC Live', text)
    text = re.sub('TonyAbbottMHR', 'Tony Abbott', text)
    text = re.sub('paulmyerscough', 'Paul Myerscough', text)
    text = re.sub('georgegallagher', 'George Gallagher', text)
    text = re.sub('JimmieJohnson', 'Jimmie Johnson', text)
    text = re.sub('pctool', 'pc tool', text)
    text = re.sub('DoingHashtagsRight', 'Doing Hashtags Right', text)
    text = re.sub('ThrowbackThursday', 'Throwback Thursday', text)
    text = re.sub('SnowBackSunday', 'Snowback Sunday', text)
    text = re.sub('LakeEffect', 'Lake Effect', text)
    text = re.sub('RTphotographyUK', 'Richard Thomas Photography UK', text)
    text = re.sub('BigBang_CBS', 'Big Bang CBS', text)
    text = re.sub('writerslife', 'writers life', text)
    text = re.sub('NaturalBirth', 'Natural Birth', text)
    text = re.sub('UnusualWords', 'Unusual Words', text)
    text = re.sub('wizkhalifa', 'Wiz Khalifa', text)
    text = re.sub('acreativedc', 'a creative DC', text)
    text = re.sub('vscodc', 'vsco DC', text)
    text = re.sub('VSCOcam', 'vsco camera', text)
    text = re.sub('TheBEACHDC', 'The beach DC', text)
    text = re.sub('buildingmuseum', 'building museum', text)
    text = re.sub('WorldOil', 'World Oil', text)
    text = re.sub('redwedding', 'red wedding', text)
    text = re.sub('AmazingRaceCanada', 'Amazing Race Canada', text)
    text = re.sub('WakeUpAmerica', 'Wake Up America', text)
    text = re.sub('\\\\Allahuakbar\\\\', 'Allahu Akbar', text)
    text = re.sub('bleased', 'blessed', text)
    text = re.sub('nigeriantribune', 'Nigerian Tribune', text)
    text = re.sub('HIDEO_KOJIMA_EN', 'Hideo Kojima', text)
    text = re.sub('FusionFestival', 'Fusion Festival', text)
    text = re.sub('50Mixed', '50 Mixed', text)
    text = re.sub('NoAgenda', 'No Agenda', text)
    text = re.sub('WhiteGenocide', 'White Genocide', text)
    text = re.sub('dirtylying', 'dirty lying', text)
    text = re.sub('SyrianRefugees', 'Syrian Refugees', text)
    text = re.sub('changetheworld', 'change the world', text)
    text = re.sub('Ebolacase', 'Ebola case', text)
    text = re.sub('mcgtech', 'mcg technologies', text)
    text = re.sub('withweapons', 'with weapons', text)
    text = re.sub('advancedwarfare', 'advanced warfare', text)
    text = re.sub('letsFootball', 'let us Football', text)
    text = re.sub('LateNiteMix', 'late night mix', text)
    text = re.sub('PhilCollinsFeed', 'Phil Collins', text)
    text = re.sub('RudyHavenstein', 'Rudy Havenstein', text)
    text = re.sub('22PM', '22 PM', text)
    text = re.sub('54am', '54 AM', text)
    text = re.sub('38am', '38 AM', text)
    text = re.sub('OldFolkExplainStuff', 'Old Folk Explain Stuff', text)
    text = re.sub('BlacklivesMatter', 'Black Lives Matter', text)
    text = re.sub('InsaneLimits', 'Insane Limits', text)
    text = re.sub('youcantsitwithus', 'you cannot sit with us', text)
    text = re.sub('2k15', '2015', text)
    text = re.sub('TheIran', 'Iran', text)
    text = re.sub('JimmyFallon', 'Jimmy Fallon', text)
    text = re.sub('AlbertBrooks', 'Albert Brooks', text)
    text = re.sub('defense_news', 'defense news', text)
    text = re.sub('nuclearrcSA', 'Nuclear Risk Control Self Assessment', text)
    text = re.sub('Auspol', 'Australia Politics', text)
    text = re.sub('NuclearPower', 'Nuclear Power', text)
    text = re.sub('WhiteTerrorism', 'White Terrorism', text)
    text = re.sub('truthfrequencyradio', 'Truth Frequency Radio', text)
    text = re.sub('ErasureIsNotEquality', 'Erasure is not equality', text)
    text = re.sub('ProBonoNews', 'Pro Bono News', text)
    text = re.sub('JakartaPost', 'Jakarta Post', text)
    text = re.sub('toopainful', 'too painful', text)
    text = re.sub('melindahaunton', 'Melinda Haunton', text)
    text = re.sub('NoNukes', 'No Nukes', text)
    text = re.sub('curryspcworld', 'Currys PC World', text)
    text = re.sub('ineedcake', 'I need cake', text)
    text = re.sub('blackforestgateau', 'black forest gateau', text)
    text = re.sub('BBCOne', 'BBC One', text)
    text = re.sub('AlexxPage', 'Alex Page', text)
    text = re.sub('jonathanserrie', 'Jonathan Serrie', text)
    text = re.sub('SocialJerkBlog', 'Social Jerk Blog', text)
    text = re.sub('ChelseaVPeretti', 'Chelsea Peretti', text)
    text = re.sub('irongiant', 'iron giant', text)
    text = re.sub('RonFunches', 'Ron Funches', text)
    text = re.sub('TimCook', 'Tim Cook', text)
    text = re.sub('sebastianstanisaliveandwell', 'Sebastian Stan is alive and well', text)
    text = re.sub('Madsummer', 'Mad summer', text)
    text = re.sub('NowYouKnow', 'Now you know', text)
    text = re.sub('concertphotography', 'concert photography', text)
    text = re.sub('TomLandry', 'Tom Landry', text)
    text = re.sub('showgirldayoff', 'show girl day off', text)
    text = re.sub('Yougslavia', 'Yugoslavia', text)
    text = re.sub('QuantumDataInformatics', 'Quantum Data Informatics', text)
    text = re.sub('FromTheDesk', 'From The Desk', text)
    text = re.sub('TheaterTrial', 'Theater Trial', text)
    text = re.sub('CatoInstitute', 'Cato Institute', text)
    text = re.sub('EmekaGift', 'Emeka Gift', text)
    text = re.sub('LetsBe_Rational', 'Let us be rational', text)
    text = re.sub('Cynicalreality', 'Cynical reality', text)
    text = re.sub('FredOlsenCruise', 'Fred Olsen Cruise', text)
    text = re.sub('NotSorry', 'not sorry', text)
    text = re.sub('UseYourWords', 'use your words', text)
    text = re.sub('WordoftheDay', 'word of the day', text)
    text = re.sub('Dictionarycom', 'Dictionary.com', text)
    text = re.sub('TheBrooklynLife', 'The Brooklyn Life', text)
    text = re.sub('jokethey', 'joke they', text)
    text = re.sub('nflweek1picks', 'NFL week 1 picks', text)
    text = re.sub('uiseful', 'useful', text)
    text = re.sub('JusticeDotOrg', 'The American Association for Justice', text)
    text = re.sub('autoaccidents', 'auto accidents', text)
    text = re.sub('SteveGursten', 'Steve Gursten', text)
    text = re.sub('MichiganAutoLaw', 'Michigan Auto Law', text)
    text = re.sub('birdgang', 'bird gang', text)
    text = re.sub('nflnetwork', 'NFL Network', text)
    text = re.sub('NYDNSports', 'NY Daily News Sports', text)
    text = re.sub('RVacchianoNYDN', 'Ralph Vacchiano NY Daily News', text)
    text = re.sub('EdmontonEsks', 'Edmonton Eskimos', text)
    text = re.sub('david_brelsford', 'David Brelsford', text)
    text = re.sub('TOI_India', 'The Times of India', text)
    text = re.sub('hegot', 'he got', text)
    text = re.sub('SkinsOn9', 'Skins on 9', text)
    text = re.sub('sothathappened', 'so that happened', text)
    text = re.sub('LCOutOfDoors', 'LC Out Of Doors', text)
    text = re.sub('NationFirst', 'Nation First', text)
    text = re.sub('IndiaToday', 'India Today', text)
    text = re.sub('HLPS', 'helps', text)
    text = re.sub('HOSTAGESTHROSW', 'hostages throw', text)
    text = re.sub('SNCTIONS', 'sanctions', text)
    text = re.sub('BidTime', 'Bid Time', text)
    text = re.sub('crunchysensible', 'crunchy sensible', text)
    text = re.sub('RandomActsOfRomance', 'Random acts of romance', text)
    text = re.sub('MomentsAtHill', 'Moments at hill', text)
    text = re.sub('eatshit', 'eat shit', text)
    text = re.sub('liveleakfun', 'live leak fun', text)
    text = re.sub('SahelNews', 'Sahel News', text)
    text = re.sub('abc7newsbayarea', 'ABC 7 News Bay Area', text)
    text = re.sub('facilitiesmanagement', 'facilities management', text)
    text = re.sub('facilitydude', 'facility dude', text)
    text = re.sub('CampLogistics', 'Camp logistics', text)
    text = re.sub('alaskapublic', 'Alaska public', text)
    text = re.sub('MarketResearch', 'Market Research', text)
    text = re.sub('AccuracyEsports', 'Accuracy Esports', text)
    text = re.sub('TheBodyShopAust', 'The Body Shop Australia', text)
    text = re.sub('yychail', 'Calgary hail', text)
    text = re.sub('yyctraffic', 'Calgary traffic', text)
    text = re.sub('eliotschool', 'eliot school', text)
    text = re.sub('TheBrokenCity', 'The Broken City', text)
    text = re.sub('OldsFireDept', 'Olds Fire Department', text)
    text = re.sub('RiverComplex', 'River Complex', text)
    text = re.sub('fieldworksmells', 'field work smells', text)
    text = re.sub('IranElection', 'Iran Election', text)
    text = re.sub('glowng', 'glowing', text)
    text = re.sub('kindlng', 'kindling', text)
    text = re.sub('riggd', 'rigged', text)
    text = re.sub('slownewsday', 'slow news day', text)
    text = re.sub('MyanmarFlood', 'Myanmar Flood', text)
    text = re.sub('abc7chicago', 'ABC 7 Chicago', text)
    text = re.sub('copolitics', 'Colorado Politics', text)
    text = re.sub('AdilGhumro', 'Adil Ghumro', text)
    text = re.sub('netbots', 'net bots', text)
    text = re.sub('byebyeroad', 'bye bye road', text)
    text = re.sub('massiveflooding', 'massive flooding', text)
    text = re.sub('EndofUS', 'End of United States', text)
    text = re.sub('35PM', '35 PM', text)
    text = re.sub('greektheatrela', 'Greek Theatre Los Angeles', text)
    text = re.sub('76mins', '76 minutes', text)
    text = re.sub('publicsafetyfirst', 'public safety first', text)
    text = re.sub('livesmatter', 'lives matter', text)
    text = re.sub('myhometown', 'my hometown', text)
    text = re.sub('tankerfire', 'tanker fire', text)
    text = re.sub('MEMORIALDAY', 'memorial day', text)
    text = re.sub('MEMORIAL_DAY', 'memorial day', text)
    text = re.sub('instaxbooty', 'instagram booty', text)
    text = re.sub('Jerusalem_Post', 'Jerusalem Post', text)
    text = re.sub('WayneRooney_INA', 'Wayne Rooney', text)
    text = re.sub('VirtualReality', 'Virtual Reality', text)
    text = re.sub('OculusRift', 'Oculus Rift', text)
    text = re.sub('OwenJones84', 'Owen Jones', text)
    text = re.sub('jeremycorbyn', 'Jeremy Corbyn', text)
    text = re.sub('paulrogers002', 'Paul Rogers', text)
    text = re.sub('mortalkombatx', 'Mortal Kombat X', text)
    text = re.sub('mortalkombat', 'Mortal Kombat', text)
    text = re.sub('FilipeCoelho92', 'Filipe Coelho', text)
    text = re.sub('OnlyQuakeNews', 'Only Quake News', text)
    text = re.sub('kostumes', 'costumes', text)
    text = re.sub('YEEESSSS', 'yes', text)
    text = re.sub('ToshikazuKatayama', 'Toshikazu Katayama', text)
    text = re.sub('IntlDevelopment', 'Intl Development', text)
    text = re.sub('ExtremeWeather', 'Extreme Weather', text)
    text = re.sub('WereNotGruberVoters', 'We are not gruber voters', text)
    text = re.sub('NewsThousands', 'News Thousands', text)
    text = re.sub('EdmundAdamus', 'Edmund Adamus', text)
    text = re.sub('EyewitnessWV', 'Eye witness WV', text)
    text = re.sub('PhiladelphiaMuseu', 'Philadelphia Museum', text)
    text = re.sub('DublinComicCon', 'Dublin Comic Con', text)
    text = re.sub('NicholasBrendon', 'Nicholas Brendon', text)
    text = re.sub('Alltheway80s', 'All the way 80s', text)
    text = re.sub('FromTheField', 'From the field', text)
    text = re.sub('NorthIowa', 'North Iowa', text)
    text = re.sub('WillowFire', 'Willow Fire', text)
    text = re.sub('MadRiverComplex', 'Mad River Complex', text)
    text = re.sub('feelingmanly', 'feeling manly', text)
    text = re.sub('stillnotoverit', 'still not over it', text)
    text = re.sub('FortitudeValley', 'Fortitude Valley', text)
    text = re.sub('CoastpowerlineTramTr', 'Coast powerline', text)
    text = re.sub('ServicesGold', 'Services Gold', text)
    text = re.sub('NewsbrokenEmergency', 'News broken emergency', text)
    text = re.sub('Evaucation', 'evacuation', text)
    text = re.sub('leaveevacuateexitbe', 'leave evacuate exit be', text)
    text = re.sub('P_EOPLE', 'PEOPLE', text)
    text = re.sub('Tubestrike', 'tube strike', text)
    text = re.sub('CLASS_SICK', 'CLASS SICK', text)
    text = re.sub('localplumber', 'local plumber', text)
    text = re.sub('awesomejobsiri', 'awesome job siri', text)
    text = re.sub('PayForItHow', 'Pay for it how', text)
    text = re.sub('ThisIsAfrica', 'This is Africa', text)
    text = re.sub('crimeairnetwork', 'crime air network', text)
    text = re.sub('KimAcheson', 'Kim Acheson', text)
    text = re.sub('cityofcalgary', 'City of Calgary', text)
    text = re.sub('prosyndicate', 'pro syndicate', text)
    text = re.sub('660NEWS', '660 NEWS', text)
    text = re.sub('BusInsMagazine', 'Business Insurance Magazine', text)
    text = re.sub('wfocus', 'focus', text)
    text = re.sub('ShastaDam', 'Shasta Dam', text)
    text = re.sub('go2MarkFranco', 'Mark Franco', text)
    text = re.sub('StephGHinojosa', 'Steph Hinojosa', text)
    text = re.sub('Nashgrier', 'Nash Grier', text)
    text = re.sub('NashNewVideo', 'Nash new video', text)
    text = re.sub('IWouldntGetElectedBecause', 'I would not get elected because', text)
    text = re.sub('SHGames', 'Sledgehammer Games', text)
    text = re.sub('bedhair', 'bed hair', text)
    text = re.sub('JoelHeyman', 'Joel Heyman', text)
    text = re.sub('viaYouTube', 'via YouTube', text)
    text = re.sub('https?:\\/\\/t.co\\/[A-Za-z0-9]+', '', text)
    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + "'`"
    for p in punctuations:
        text = text.replace(p, f' {p} ')
    text = text.replace('...', ' ... ')
    if '...' not in text:
        text = text.replace('..', ' ... ')
    text = re.sub('MH370', 'Malaysia Airlines Flight 370', text)
    text = re.sub('mÌ¼sica', 'music', text)
    text = re.sub('okwx', 'Oklahoma City Weather', text)
    text = re.sub('arwx', 'Arkansas Weather', text)
    text = re.sub('gawx', 'Georgia Weather', text)
    text = re.sub('scwx', 'South Carolina Weather', text)
    text = re.sub('cawx', 'California Weather', text)
    text = re.sub('tnwx', 'Tennessee Weather', text)
    text = re.sub('azwx', 'Arizona Weather', text)
    text = re.sub('alwx', 'Alabama Weather', text)
    text = re.sub('wordpressdotcom', 'wordpress', text)
    text = re.sub('usNWSgov', 'United States National Weather Service', text)
    text = re.sub('Suruc', 'Sanliurfa', text)
    text = re.sub('Bestnaijamade', 'bestnaijamade', text)
    text = re.sub('SOUDELOR', 'Soudelor', text)
    return text
train_clean = train.copy()
test_clean = test.copy()
train_clean['text'] = train_clean['text'].apply(lambda x: clean_text(x))
test_clean['text'] = test_clean['text'].apply(lambda x: clean_text(x))

def text_after_preprocess(before_text, after_text):
    """
    Input- before_text=text column before cleanup
              after_text= text column after cleanup
       Output- print before and after text to compare how it looks after cleanup
       
    """
    print('-' * 60)
    print('Text before cleanup')
    print('-' * 60)
    print(before_text.head(5))
    print('-' * 60)
    print('Text after cleanup')
    print('-' * 60)
    print(after_text.head(5))
text_after_preprocess(train.text, train_clean.text)
text_after_preprocess(test.text, test_clean.text)
train_clean.head()
train_clean.head()
stop_words = set(stopwords.words('english'))

def preprocess(text):
    text = ' '.join([w.lower() for w in word_tokenize(re.sub('[^a-zA-Z]+', ' ', text)) if not w in stop_words])
    return text
train_clean['text_2'] = train_clean.apply(lambda x: preprocess(x['text']), axis=1)
test_clean['text_2'] = test_clean.apply(lambda x: preprocess(x['text']), axis=1)
train_clean.head()
tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')
train_clean['text_token'] = train_clean['text_2'].apply(lambda x: tokenizer.tokenize(x))
test_clean['text_token'] = test_clean['text_2'].apply(lambda x: tokenizer.tokenize(x))
from nltk.stem.snowball import SnowballStemmer
stemmer = SnowballStemmer('english')
train_clean['stemmed'] = train_clean['text_token'].apply(lambda x: [stemmer.stem(y) for y in x])
test_clean['stemmed'] = test_clean['text_token'].apply(lambda x: [stemmer.stem(y) for y in x])
train_clean.head()
train_clean.head()
test_clean.head()
train_clean['stemmed_text'] = [' '.join(map(str, l)) for l in train_clean['stemmed']]
test_clean['stemmed_text'] = [' '.join(map(str, l)) for l in test_clean['stemmed']]
train_clean.head()
count_vectorizer = CountVectorizer()
train_cv = count_vectorizer.fit_transform(train_clean['text_2'])
train_stemmed_cv = count_vectorizer.fit_transform(train_clean['stemmed_text'])
test_cv = count_vectorizer.fit_transform(test_clean['text_2'])
test_stemmed_cv = count_vectorizer.fit_transform(test_clean['stemmed_text'])
print(train_cv[0].todense())
tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))
train_tf = tfidf.fit_transform(train_clean['text_2'])
train_stemmed_tf = tfidf.fit_transform(train_clean['stemmed_text'])
test_tf = tfidf.transform(test_clean['text_2'])
test_stemmed_tf = tfidf.fit_transform(test_clean['stemmed_text'])

def fit_and_predict(model, X_train, y_train, X_test, y_test):
    """Input- model=model to be trained
              X_train, y_train= traing data set
              X_test,  y_test = testing data set
       Output- Print accuracy of model for training and test data sets   
    """
    clf = model