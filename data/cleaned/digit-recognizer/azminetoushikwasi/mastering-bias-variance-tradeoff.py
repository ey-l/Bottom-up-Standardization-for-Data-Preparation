import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import timedelta
import warnings
from scipy import stats
import random
import os
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
import plotly.express as px
from sklearn.metrics import mean_squared_error
warnings.filterwarnings('ignore')
init_notebook_mode(connected=True)
rows = 1000
random_x = np.random.randn(rows)
random_y = (random_x ** 5 + -2 * random_x ** 4 - 4.2 * random_x ** 3 + 20 * random_x ** 2 + 6 ** random_x + 2).reshape(rows, 1)
test_df = pd.read_csv('data/input/digit-recognizer/test.csv')
sns.heatmap(test_df.corr())
random_y.mean()
mylist = []
for i in range(0, 320):
    x = random.randint(25, 100)
    mylist.append(x)
random_y[0:20] = random_y[0:20] - 100
random_y[100:140] = random_y[100:140] - 30
random_y[900:920] = random_y[900:920] - 20
random_y[200:520] = random_y[200:520] + np.array(mylist).reshape(320, 1)
random_y[500:520] = random_y[500:520] - 50
random_y[600:640] = random_y[600:640] - 25
sns.set(rc={'figure.figsize': (15, 5)})
for (i, column) in enumerate([random_x, random_y], 1):
    plt.subplot(1, 2, i)
    sns.distplot(column, color='tomato', fit_kws={'color': 'indigo'}, fit=stats.gamma, label='label 1')
test_size = int(np.round(rows * 0.2, 0))
x_train = random_x[:-test_size]
y_train = random_y[:-test_size]
x_test = random_x[-test_size:]
y_test = random_y[-test_size:]
(fig, ax) = plt.subplots(figsize=(12, 7))
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.8)
ax.scatter(x_train, y_train, color='navy')

linear_regression_model = np.polyfit(x_train, y_train, deg=1)
linear_model_predictions = np.polyval(linear_regression_model, x_test)
linear_model_predictions_train = np.polyval(linear_regression_model, x_train)
(fig, ax) = plt.subplots(figsize=(12, 7))
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.7)
main = ax.scatter(random_x, random_y, color='grey', alpha=0.2, linewidth=6)
plt.plot(x_test, linear_model_predictions, color='firebrick', linewidth=3)


def get_bias(predicted_values, true_values):
    return np.round(np.mean((predicted_values - true_values) ** 2), 0)

def get_variance(values):
    return np.round(np.var(values), 0)

def get_metrics(target_train, target_test, model_train_predictions, model_test_predictions):
    training_mse = mean_squared_error(target_train, model_train_predictions)
    test_mse = mean_squared_error(target_test, model_test_predictions)
    bias = get_bias(model_test_predictions, target_test)
    variance = get_variance(model_test_predictions)
    linear_regression_model = np.polyfit(x_train, y_train, deg=1)
    return [training_mse, test_mse, bias, variance]
degree = []
training_mse = []
test_mse = []
bias = []
variance = []
linear_model_predictions = np.polyval(linear_regression_model, x_test)
training_linear_model_predictions = np.polyval(linear_regression_model, x_train)
(linear_training_mse, linear_test_mse, linear_bias, linear_variance) = get_metrics(y_train, y_test, training_linear_model_predictions, linear_model_predictions)
degree.append(1)
training_mse.append(linear_training_mse)
test_mse.append(linear_test_mse)
bias.append(linear_bias)
variance.append(linear_variance)
print('Simple linear model')
print('- Training MSE %0.f' % linear_training_mse)
print('- Test MSE %0.f' % linear_test_mse)
print('- Bias %0.f' % linear_bias)
print('- Variance %0.f' % linear_variance)
polynomial_2nd_model = np.polyfit(x_train, y_train, deg=2)
p_2nd = np.poly1d(polynomial_2nd_model.reshape(1, 3)[0])
print('Coefficients %s\n' % p_2nd)
polynomial_2nd_predictions = np.polyval(polynomial_2nd_model, x_test)
training_polynomial_2nd_predictions = np.polyval(polynomial_2nd_model, x_train)
(polynomial_2nd_training_mse, polynomial_2nd_test_mse, polynomial_2nd_bias, polynomial_2nd_variance) = get_metrics(y_train, y_test, training_polynomial_2nd_predictions, polynomial_2nd_predictions)
degree.append(2)
training_mse.append(polynomial_2nd_training_mse)
test_mse.append(polynomial_2nd_test_mse)
bias.append(polynomial_2nd_bias)
variance.append(polynomial_2nd_variance)
print('2nd degree polynomial')
print('Training MSE %0.f' % polynomial_2nd_training_mse)
print('Test MSE %0.f' % polynomial_2nd_test_mse)
print('Bias %0.f' % polynomial_2nd_bias)
print('Variance %0.f' % polynomial_2nd_variance)
(fig, ax) = plt.subplots(figsize=(12, 7))
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)
x_linspace = np.linspace(min(random_x), max(random_x), num=len(polynomial_2nd_predictions))
main = ax.scatter(random_x, random_y, color='grey', alpha=0.2, linewidth=6)
first = plt.plot(x_test, linear_model_predictions, color='firebrick', linewidth=1)
second = plt.plot(x_linspace, p_2nd(x_linspace), '-', color='gold', linewidth=3)
plt.legend([first[:1], second[:1]], ['First Degree'])
plt.legend(second[:1], ['Second Degree'])
polynomial_4thdeg_model = np.polyfit(x_train, y_train, deg=4)
p_4th = np.poly1d(polynomial_4thdeg_model.reshape(1, 5)[0])
print('Coefficients %s\n' % p_4th)
polynomial_4thdeg_predictions = np.polyval(polynomial_4thdeg_model, x_test)
training_polynomial_4thdeg_predictions = np.polyval(polynomial_4thdeg_model, x_train)
(polynomial_4thdeg_training_mse, polynomial_4thdeg_test_mse, polynomial_4thdeg_bias, polynomial_4thdeg_variance) = get_metrics(y_train, y_test, training_polynomial_4thdeg_predictions, polynomial_4thdeg_predictions)
degree.append(4)
training_mse.append(polynomial_4thdeg_training_mse)
test_mse.append(polynomial_4thdeg_test_mse)
bias.append(polynomial_4thdeg_bias)
variance.append(polynomial_4thdeg_variance)
print('4th degree polynomial')
print('Training MSE %0.f' % polynomial_4thdeg_training_mse)
print('Test MSE %0.f' % polynomial_4thdeg_test_mse)
print('Bias %0.f' % polynomial_4thdeg_bias)
print('Variance %0.f' % polynomial_4thdeg_variance)
(fig, ax) = plt.subplots(figsize=(12, 7))
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)
x_linspace = np.linspace(min(random_x), max(random_x), num=len(polynomial_2nd_predictions))
main = ax.scatter(random_x, random_y, color='grey', alpha=0.2, linewidth=6)
first = plt.plot(x_test, linear_model_predictions, color='firebrick', linewidth=1)
second = plt.plot(x_linspace, p_2nd(x_linspace), '-', color='gold', linewidth=1)
fourth = plt.plot(x_linspace, p_4th(x_linspace), '-', color='green', linewidth=3)
plt.legend(fourth[:1], ['4th Degree'])
polynomial_5thdeg_model = np.polyfit(x_train, y_train, deg=5)
p_5th = np.poly1d(polynomial_5thdeg_model.reshape(1, 6)[0])
polynomial_5thdeg_predictions = np.polyval(polynomial_5thdeg_model, x_test)
training_polynomial_5thdeg_predictions = np.polyval(polynomial_5thdeg_model, x_train)
(polynomial_5thdeg_training_mse, polynomial_5thdeg_test_mse, polynomial_5thdeg_bias, polynomial_5thdeg_variance) = get_metrics(y_train, y_test, training_polynomial_5thdeg_predictions, polynomial_5thdeg_predictions)
degree.append(5)
training_mse.append(polynomial_5thdeg_training_mse)
test_mse.append(polynomial_5thdeg_test_mse)
bias.append(polynomial_5thdeg_bias)
variance.append(polynomial_5thdeg_variance)
print('5th degree polynomial')
print('Training MSE %0.f' % polynomial_5thdeg_training_mse)
print('Test MSE %0.f' % polynomial_5thdeg_test_mse)
print('Bias %0.f' % polynomial_5thdeg_bias)
print('Variance %0.f' % polynomial_5thdeg_variance)
(fig, ax) = plt.subplots(figsize=(12, 7))
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.1)
x_linspace = np.linspace(min(random_x), max(random_x), num=len(polynomial_2nd_predictions))
main = ax.scatter(random_x, random_y, color='grey', alpha=0.6, linewidth=6)
first = plt.plot(x_test, linear_model_predictions, color='firebrick', linewidth=1)
second = plt.plot(x_linspace, p_2nd(x_linspace), '-', color='gold', linewidth=1)
fourth = plt.plot(x_linspace, p_4th(x_linspace), '-', color='green', linewidth=1)
fifth = plt.plot(x_linspace, p_5th(x_linspace), '-', color='red', linewidth=3)
plt.legend(fifth[:1], ['5th Degree'])
polynomial_8thdeg_model = np.polyfit(x_train, y_train, deg=8)
p_8th = np.poly1d(polynomial_5thdeg_model.reshape(1, 6)[0])
polynomial_8thdeg_predictions = np.polyval(polynomial_8thdeg_model, x_test)
training_polynomial_8thdeg_predictions = np.polyval(polynomial_8thdeg_model, x_train)
polynomial_80thdeg_model = np.polyfit(x_train, y_train, deg=20)
p_80th = np.poly1d(polynomial_80thdeg_model.reshape(1, 21)[0])
polynomial_80thdeg_predictions = np.polyval(polynomial_80thdeg_model, x_test)
training_polynomial_80thdeg_predictions = np.polyval(polynomial_80thdeg_model, x_train)
(polynomial_8thdeg_training_mse, polynomial_8thdeg_test_mse, polynomial_8thdeg_bias, polynomial_8thdeg_variance) = get_metrics(y_train, y_test, training_polynomial_8thdeg_predictions, polynomial_8thdeg_predictions)
degree.append(8)
training_mse.append(polynomial_8thdeg_training_mse)
test_mse.append(polynomial_8thdeg_test_mse)
bias.append(polynomial_8thdeg_bias)
variance.append(polynomial_8thdeg_variance)
print('8th degree polynomial')
print('Training MSE %0.f' % polynomial_8thdeg_training_mse)
print('Test MSE %0.f' % polynomial_8thdeg_test_mse)
print('Bias %0.f' % polynomial_8thdeg_bias)
print('Variance %0.f' % polynomial_8thdeg_variance)
(polynomial_80thdeg_training_mse, polynomial_80thdeg_test_mse, polynomial_80thdeg_bias, polynomial_80thdeg_variance) = get_metrics(y_train, y_test, training_polynomial_80thdeg_predictions, polynomial_80thdeg_predictions)
degree.append(20)
training_mse.append(polynomial_80thdeg_training_mse)
test_mse.append(polynomial_80thdeg_test_mse)
bias.append(polynomial_80thdeg_bias)
variance.append(polynomial_80thdeg_variance)
print('80th degree polynomial')
print('Training MSE %0.f' % polynomial_80thdeg_training_mse)
print('Test MSE %0.f' % polynomial_80thdeg_test_mse)
print('Bias %0.f' % polynomial_80thdeg_bias)
print('Variance %0.f' % polynomial_80thdeg_variance)
(fig, ax) = plt.subplots(figsize=(12, 7))
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)
x_linspace = np.linspace(min(random_x), max(random_x), num=len(polynomial_2nd_predictions))
main = ax.scatter(random_x, random_y, color='grey', alpha=0.2, linewidth=6)
first = plt.plot(x_test, linear_model_predictions, color='firebrick', linewidth=1)
second = plt.plot(x_linspace, p_2nd(x_linspace), '-', color='gold', linewidth=1)
fourth = plt.plot(x_linspace, p_4th(x_linspace), '-', color='green', linewidth=1)
fifth = plt.plot(x_linspace, p_5th(x_linspace), '-', color='red', linewidth=1)
eighth = plt.plot(x_linspace, p_8th(x_linspace), '-', color='blue', linewidth=3)
plt.legend(fourth[:1], ['8th Degree'])
(fig, ax) = plt.subplots(figsize=(12, 7))
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)
x_linspace = np.linspace(min(random_x), max(random_x), num=len(polynomial_2nd_predictions))
main = ax.scatter(random_x, random_y, color='grey', alpha=0.2, linewidth=6)
first = plt.plot(x_test, linear_model_predictions, color='firebrick', linewidth=1)
second = plt.plot(x_linspace, p_2nd(x_linspace), '-', color='gold', linewidth=1)
fourth = plt.plot(x_linspace, p_4th(x_linspace), '-', color='green', linewidth=1)
fifth = plt.plot(x_linspace, p_5th(x_linspace), '-', color='red', linewidth=1)
eighth = plt.plot(x_linspace, p_8th(x_linspace), '-', color='blue', linewidth=1)
eighthy = plt.plot(x_linspace, p_80th(x_linspace), '-', color='purple', linewidth=3)
plt.legend(fourth[:1], ['20th Degree'])
lst = [degree, training_mse, test_mse, bias, variance]
metrics_df = pd.DataFrame(lst)
metrics_df = metrics_df.T
metrics_df.rename(columns={0: 'degree', 1: 'training_mse', 2: 'test_mse', 3: 'bias', 4: 'variance'}, inplace=True)
metrics_df
metrics_df.describe()
plt.figure(figsize=(10, 10))
trace1 = go.Scatter(x=metrics_df.degree, y=metrics_df.training_mse, name='Training', line=dict(color='green'), opacity=0.9, marker=dict(color='white', size=10, line=dict(width=5)))
trace2 = go.Scatter(x=metrics_df.degree, y=metrics_df.test_mse, name='Test', line=dict(color='red'), opacity=0.9, marker=dict(color='white', size=10, line=dict(width=5)))
layout2 = dict(title='Mean Squared Error')
fig2 = dict(data=[trace1, trace2], layout=layout2)
iplot(fig2)
plt.figure(figsize=(10, 10))
Bias = go.Scatter(x=metrics_df.degree, y=metrics_df.bias, name='Bias', line=dict(color='darkorange'), opacity=1, marker=dict(color='white', size=10, line=dict(width=12)))
layout2 = dict(title='Bias')
fig = dict(data=[Bias], layout=layout2)
iplot(fig)
plt.figure(figsize=(10, 10))
Variance = go.Scatter(x=metrics_df.degree, y=metrics_df.variance, name='Variance', line=dict(color='indigo'), opacity=1, marker=dict(color='white', size=10, line=dict(width=12)))
layout2 = dict(title='Variance')
fig = dict(data=[Variance], layout=layout2)
iplot(fig)
layout = dict(title='Bias - Variance')
fig = dict(data=[Bias, Variance], layout=layout)
iplot(fig)
test_df.describe()